<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.75">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>computational-linear-algebra - 1. Why are we here?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: 1;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="computational-linear-algebra - 1. Why are we here?">
<meta property="og:description" content="You can read an overview of this Numerical Linear Algebra course in this blog post. The course was originally taught in the University of San Francisco MS in Analytics graduate program.">
<meta property="og:site-name" content="computational-linear-algebra">
<meta name="twitter:title" content="computational-linear-algebra - 1. Why are we here?">
<meta name="twitter:description" content="You can read an overview of this Numerical Linear Algebra course in this blog post. The course was originally taught in the University of San Francisco MS in Analytics graduate program.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">computational-linear-algebra</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/xrsrke/computational-linear-algebra"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">1. Why are we here?</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">computational-linear-algebra</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../core.html" class="sidebar-item-text sidebar-link">core</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../01_matrix_math_accuracy_memory_speed_parallelization.html" class="sidebar-item-text sidebar-link">1. Matrix Math, Accuracy, Memory, Speed, &amp; Parallelization</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">fastai_nbs</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/0. Course Logistics.html" class="sidebar-item-text sidebar-link">0. Course Logistics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/1. Why are we here.html" class="sidebar-item-text sidebar-link active">1. Why are we here?</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/2. Topic Modeling with NMF and SVD.html" class="sidebar-item-text sidebar-link">2. Topic Modeling with NMF and SVD</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/3. Background Removal with Robust PCA.html" class="sidebar-item-text sidebar-link">3. Background Removal with Robust PCA</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/4. Compressed Sensing of CT Scans with Robust Regression.html" class="sidebar-item-text sidebar-link">4. Compressed Sensing of CT Scans with Robust Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/5. Health Outcomes with Linear Regression.html" class="sidebar-item-text sidebar-link">5. Health Outcomes with Linear Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/6. How to Implement Linear Regression.html" class="sidebar-item-text sidebar-link">6. How to Implement Linear Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/7. PageRank with Eigen Decompositions.html" class="sidebar-item-text sidebar-link">7. PageRank with Eigen Decompositions</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/8. Implementing QR Factorization.html" class="sidebar-item-text sidebar-link">8. Implementing QR Factorization</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/Homework 1.html" class="sidebar-item-text sidebar-link">Homework 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/Homework 2.html" class="sidebar-item-text sidebar-link">Homework 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/Homework 3.html" class="sidebar-item-text sidebar-link">Homework 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/convolution-intro.html" class="sidebar-item-text sidebar-link">Intro to Convolutions</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fastai_nbs/gradient-descent-intro.html" class="sidebar-item-text sidebar-link">Gradient Descent Intro</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#why-study-numerical-linear-algebra" id="toc-why-study-numerical-linear-algebra" class="nav-link active" data-scroll-target="#why-study-numerical-linear-algebra">Why study Numerical Linear Algebra?</a>
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  </ul></li>
  <li><a href="#matrix-computations" id="toc-matrix-computations" class="nav-link" data-scroll-target="#matrix-computations">Matrix Computations</a>
  <ul>
  <li><a href="#matrix-and-tensor-products" id="toc-matrix-and-tensor-products" class="nav-link" data-scroll-target="#matrix-and-tensor-products">Matrix and Tensor Products</a>
  <ul class="collapse">
  <li><a href="#matrix-vector-products" id="toc-matrix-vector-products" class="nav-link" data-scroll-target="#matrix-vector-products">Matrix-Vector Products:</a></li>
  <li><a href="#answer" id="toc-answer" class="nav-link" data-scroll-target="#answer">Answer</a></li>
  <li><a href="#matrix-matrix-products" id="toc-matrix-matrix-products" class="nav-link" data-scroll-target="#matrix-matrix-products">Matrix-Matrix Products</a></li>
  <li><a href="#answer-1" id="toc-answer-1" class="nav-link" data-scroll-target="#answer-1">Answer</a></li>
  <li><a href="#image-data" id="toc-image-data" class="nav-link" data-scroll-target="#image-data">Image Data</a></li>
  <li><a href="#convolution" id="toc-convolution" class="nav-link" data-scroll-target="#convolution">Convolution</a></li>
  </ul></li>
  <li><a href="#matrix-decompositions" id="toc-matrix-decompositions" class="nav-link" data-scroll-target="#matrix-decompositions">Matrix Decompositions</a></li>
  </ul></li>
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy">Accuracy</a>
  <ul>
  <li><a href="#floating-point-arithmetic" id="toc-floating-point-arithmetic" class="nav-link" data-scroll-target="#floating-point-arithmetic">Floating Point Arithmetic</a>
  <ul class="collapse">
  <li><a href="#exercise" id="toc-exercise" class="nav-link" data-scroll-target="#exercise">Exercise</a></li>
  <li><a href="#problem-math-is-continuous-infinite-but-computers-are-discrete-finite" id="toc-problem-math-is-continuous-infinite-but-computers-are-discrete-finite" class="nav-link" data-scroll-target="#problem-math-is-continuous-infinite-but-computers-are-discrete-finite">Problem: math is continuous &amp; infinite, but computers are discrete &amp; finite</a></li>
  <li><a href="#history" id="toc-history" class="nav-link" data-scroll-target="#history">History</a></li>
  </ul></li>
  <li><a href="#conditioning-and-stability" id="toc-conditioning-and-stability" class="nav-link" data-scroll-target="#conditioning-and-stability">Conditioning and Stability</a></li>
  <li><a href="#approximation-accuracy" id="toc-approximation-accuracy" class="nav-link" data-scroll-target="#approximation-accuracy">Approximation accuracy</a></li>
  <li><a href="#expensive-errors" id="toc-expensive-errors" class="nav-link" data-scroll-target="#expensive-errors">Expensive Errors</a></li>
  </ul></li>
  <li><a href="#memory-use" id="toc-memory-use" class="nav-link" data-scroll-target="#memory-use">Memory Use</a>
  <ul>
  <li><a href="#sparse-vs-dense" id="toc-sparse-vs-dense" class="nav-link" data-scroll-target="#sparse-vs-dense">Sparse vs Dense</a></li>
  </ul></li>
  <li><a href="#speed" id="toc-speed" class="nav-link" data-scroll-target="#speed">Speed</a>
  <ul>
  <li><a href="#computational-complexity" id="toc-computational-complexity" class="nav-link" data-scroll-target="#computational-complexity">Computational complexity</a></li>
  <li><a href="#vectorization" id="toc-vectorization" class="nav-link" data-scroll-target="#vectorization">Vectorization</a>
  <ul class="collapse">
  <li><a href="#matrix-computation-packages-blas-and-lapack" id="toc-matrix-computation-packages-blas-and-lapack" class="nav-link" data-scroll-target="#matrix-computation-packages-blas-and-lapack">Matrix Computation Packages: BLAS and LAPACK</a></li>
  </ul></li>
  <li><a href="#locality" id="toc-locality" class="nav-link" data-scroll-target="#locality">Locality</a>
  <ul class="collapse">
  <li><a href="#speed-of-different-types-of-memory" id="toc-speed-of-different-types-of-memory" class="nav-link" data-scroll-target="#speed-of-different-types-of-memory">Speed of different types of memory</a></li>
  <li><a href="#temporaries" id="toc-temporaries" class="nav-link" data-scroll-target="#temporaries">Temporaries</a></li>
  </ul></li>
  <li><a href="#scaling-to-multiple-cores-and-nodes" id="toc-scaling-to-multiple-cores-and-nodes" class="nav-link" data-scroll-target="#scaling-to-multiple-cores-and-nodes">Scaling to multiple cores and nodes</a></li>
  </ul></li>
  <li><a href="#scalability-parallelization" id="toc-scalability-parallelization" class="nav-link" data-scroll-target="#scalability-parallelization">Scalability / parallelization</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/xrsrke/computational-linear-algebra/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">1. Why are we here?</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>You can read an overview of this Numerical Linear Algebra course in <a href="http://www.fast.ai/2017/07/17/num-lin-alg/">this blog post</a>. The course was originally taught in the <a href="https://www.usfca.edu/arts-sciences/graduate-programs/analytics">University of San Francisco MS in Analytics</a> graduate program. Course lecture videos are <a href="https://www.youtube.com/playlist?list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY">available on YouTube</a> (note that the notebook numbers and video numbers do not line up, since some notebooks took longer than 1 video to cover).</p>
<p>You can ask questions about the course on <a href="http://forums.fast.ai/c/lin-alg">our fast.ai forums</a>.</p>
<p><strong>Note: Future lessons have a lot more code than this one</strong></p>
<section id="why-study-numerical-linear-algebra" class="level2">
<h2 class="anchored" data-anchor-id="why-study-numerical-linear-algebra">Why study Numerical Linear Algebra?</h2>
<p><strong>Key Question of this course</strong>: How can we do matrix computations with acceptable speed and acceptable accuracy?</p>
<p>A list of the <a href="http://www.cs.fsu.edu/~lacher/courses/COT4401/notes/cise_v2_i1/index.html">Top 10 Algorithms</a> of science and engineering during the 20th century includes: the <strong>matrix decompositions</strong> approach to linear algebra. It also includes the QR algorithm, which we’ll cover, and Krylov iterative methods which we’ll see an example of. (See here for <a href="https://nickhigham.wordpress.com/2016/03/29/the-top-10-algorithms-in-applied-mathematics/">another take</a>)</p>
<p><img src="images/top10.png" alt="" style="width: 50%"> (source: <a href="http://www.cs.fsu.edu/~lacher/courses/COT4401/notes/cise_v2_i1/guest.pdf">Top 10 Algorithms</a>)</p>
<p>There are 4 things to keep in mind when choosing or designing an algorithm for matrix computations: - Memory Use - Speed - Accuracy - Scalability/Parallelization</p>
<p>Often there will be trade-offs between these categories.</p>
<section id="motivation" class="level3">
<h3 class="anchored" data-anchor-id="motivation">Motivation</h3>
<p>Matrices are everywhere– anything that can be put in an Excel spreadsheet is a matrix, and language and pictures can be represented as matrices as well. Knowing what options there are for matrix algorithms, and how to navigate compromises, can make enormous differences to your solutions. For instance, an approximate matrix computation can often be thousands of times faster than an exact one.</p>
<p>It’s not just about knowing the contents of existing libraries, but knowing how they work too. That’s because often you can make variations to an algorithm that aren’t supported by your library, giving you the performance or accuracy that you need. In addition, this field is moving very quickly at the moment, particularly in areas related to <strong>deep learning</strong>, <strong>recommendation systems</strong>, <strong>approximate algorithms</strong>, and <strong>graph analytics</strong>, so you’ll often find there’s recent results that could make big differences in your project, but aren’t in your library.</p>
<p>Knowing how the algorithms really work helps to both debug and accelerate your solution.</p>
</section>
</section>
<section id="matrix-computations" class="level2">
<h2 class="anchored" data-anchor-id="matrix-computations">Matrix Computations</h2>
<p>There are two key types of matrix computation, which get combined in many different ways. These are: - Matrix and tensor products - Matrix decompositions</p>
<p>So basically we’re going to be combining matrices, and pulling them apart again!</p>
<section id="matrix-and-tensor-products" class="level3">
<h3 class="anchored" data-anchor-id="matrix-and-tensor-products">Matrix and Tensor Products</h3>
<section id="matrix-vector-products" class="level4">
<h4 class="anchored" data-anchor-id="matrix-vector-products">Matrix-Vector Products:</h4>
<p>The matrix below gives the probabilities of moving from 1 health state to another in 1 year. If the current health states for a group are: - 85% asymptomatic - 10% symptomatic - 5% AIDS - 0% death</p>
<p>what will be the % in each health state in 1 year?</p>
<p><img src="images/markov_health.jpg" alt="floating point" style="width: 80%">(Source: <a href="https://www.youtube.com/watch?v=0Il-y_WLTo4">Concepts of Markov Chains</a>)</p>
</section>
<section id="answer" class="level4">
<h4 class="anchored" data-anchor-id="answer">Answer</h4>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Exercise: Use Numpy to compute the answer to the above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>array([[ 0.765 ],
       [ 0.1525],
       [ 0.0645],
       [ 0.018 ]])</code></pre>
</div>
</div>
</section>
<section id="matrix-matrix-products" class="level4">
<h4 class="anchored" data-anchor-id="matrix-matrix-products">Matrix-Matrix Products</h4>
<p><img src="images/shop.png" alt="floating point" style="width: 100%">(Source: <a href="https://www.mff.cuni.cz/veda/konference/wds/proc/pdf06/WDS06_106_m8_Ulrychova.pdf">Several Simple Real-world Applications of Linear Algebra Tools</a>)</p>
</section>
<section id="answer-1" class="level4">
<h4 class="anchored" data-anchor-id="answer-1">Answer</h4>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Exercise: Use Numpy to compute the answer to the above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="image-data" class="level4">
<h4 class="anchored" data-anchor-id="image-data">Image Data</h4>
<p>Images can be represented by matrices.</p>
<p><img src="images/digit.gif" alt="digit" style="width: 55%"> (Source: <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721">Adam Geitgey</a>)</p>
</section>
<section id="convolution" class="level4">
<h4 class="anchored" data-anchor-id="convolution">Convolution</h4>
<p><em>Convolutions</em> are the heart of convolutional neural networks (CNNs), a type of deep learning, responsible for the huge advances in image recognitionin the last few years. They are now increasingly being used for speech as well, such as <a href="https://code.facebook.com/posts/1978007565818999/a-novel-approach-to-neural-machine-translation/">Facebook AI’s results</a> for speech translation which are 9x faster than RNNs (the current most popular approach for speech translation).</p>
<p>Computers are now more accurate than people at classifying images.</p>
<p><img src="images/sportspredict.jpeg" alt="ImageNet" style="width: 80%"> (Source: <a href="http://karpathy.github.io/2014/07/03/feature-learning-escapades/">Andrej Karpathy</a>)</p>
<p><img src="images/InsideImagenet.png" alt="ImageNet" style="width: 80%"> (Source: <a href="https://blogs.nvidia.com/blog/2014/09/07/imagenet/">Nvidia</a>)</p>
<p>You can think of a convolution as a special kind of matrix product</p>
<p>The 3 images below are all from an excellent blog post written by a fast.ai student on <a href="https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c">CNNs from Different Viewpoints</a>:</p>
<p>A convolution applies a filter to each section of an image: <img src="images/cnn1.png" alt="CNNs" style="width: 40%"></p>
<p>Neural Network Viewpoint: <img src="images/cnn2.png" alt="CNNs" style="width: 40%"></p>
<p>Matrix Multiplication Viewpoint: <img src="images/cnn3.png" alt="CNNs" style="width: 80%"></p>
<p>Let’s see how convolutions can be used for <em>edge detection</em> in <a href="../fastai_nbs/convolution-intro.html">this notebook</a>(originally from the <a href="http://course.fast.ai/">fast.ai Deep Learning Course</a>)</p>
</section>
</section>
<section id="matrix-decompositions" class="level3">
<h3 class="anchored" data-anchor-id="matrix-decompositions">Matrix Decompositions</h3>
<p>We will be talking about Matrix Decompositions every day of this course, and will cover the below examples in future lessons:</p>
<ul>
<li><p><strong>Topic Modeling</strong> (NMF and SVD. SVD uses QR) A group of documents can be represented by a term-document matrix <img src="images/document_term.png" alt="term-document matrix" style="width: 70%"> (source: <a href="http://player.slideplayer.com/15/4528582/#">Introduction to Information Retrieval</a>) <img src="images/nmf_doc.png" alt="NMF on documents" style="width: 70%"> (source: <a href="http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf">NMF Tutorial</a>)</p></li>
<li><p><strong>Background removal</strong> (robust PCA, which uses truncated SVD) <img src="images/surveillance3.png" class="img-fluid" alt="background removal"></p></li>
<li><p><strong>Google’s PageRank Algorithm</strong> (eigen decomposition)</p></li>
</ul>
<p><img src="images/page_rank_graph.png" alt="PageRank" style="width: 70%"> (source: <a href="http://computationalculture.net/article/what_is_in_pagerank">What is in PageRank?</a>)</p>
<ul>
<li>List of other decompositions and some applications <a href="https://sites.google.com/site/igorcarron2/matrixfactorizations">matrix factorization jungle</a></li>
</ul>
</section>
</section>
<section id="accuracy" class="level2">
<h2 class="anchored" data-anchor-id="accuracy">Accuracy</h2>
<section id="floating-point-arithmetic" class="level3">
<h3 class="anchored" data-anchor-id="floating-point-arithmetic">Floating Point Arithmetic</h3>
<p>To understand accuracy, we first need to look at <strong>how</strong> computers (which are finite and discrete) store numbers (which are infinite and continuous)</p>
<section id="exercise" class="level4">
<h4 class="anchored" data-anchor-id="exercise">Exercise</h4>
<p>Take a moment to look at the function <span class="math inline">\(f\)</span> below. Before you try running it, write on paper what the output would be of <span class="math inline">\(x_1 = f(\frac{1}{10})\)</span>. Now, (still on paper) plug that back into <span class="math inline">\(f\)</span> and calculate <span class="math inline">\(x_2 = f(x_1)\)</span>. Keep going for 10 iterations.</p>
<p>This example is taken from page 107 of <em>Numerical Methods</em>, by Greenbaum and Chartier.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x <span class="op">&lt;=</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>:</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">2</span><span class="op">*</span>x <span class="op">-</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Only after you’ve written down what you think the answer should be, run the code below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">80</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(x)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> f(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What went wrong?</p>
</section>
<section id="problem-math-is-continuous-infinite-but-computers-are-discrete-finite" class="level4">
<h4 class="anchored" data-anchor-id="problem-math-is-continuous-infinite-but-computers-are-discrete-finite">Problem: math is continuous &amp; infinite, but computers are discrete &amp; finite</h4>
<p>Two Limitations of computer representations of numbers: 1. they can’t be arbitrarily large or small 2. there must be gaps between them</p>
<p>The reason we need to care about accuracy, is because computers can’t store infinitely accurate numbers. It’s possible to create calculations that give very wrong answers (particularly when repeating an operation many times, since each operation could multiply the error).</p>
<p>How computers store numbers:</p>
<p><img src="images/fpa.png" alt="floating point" style="width: 60%"></p>
<p>The <em>mantissa</em> can also be referred to as the <em>significand</em>.</p>
<p>IEEE Double precision arithmetic: - Numbers can be as large as <span class="math inline">\(1.79 \times 10^{308}\)</span> and as small as <span class="math inline">\(2.23 \times 10^{-308}\)</span>. - The interval <span class="math inline">\([1,2]\)</span> is represented by discrete subset: <span class="math display">\[1, \: 1+2^{-52}, \: 1+2 \times 2^{-52},\: 1+3 \times 2^{-52},\: \ldots, 2\]</span></p>
<ul>
<li>The interval <span class="math inline">\([2,4]\)</span> is represented: <span class="math display">\[2, \: 2+2^{-51}, \: 2+2 \times 2^{-51},\: 2+3 \times 2^{-51},\: \ldots, 4\]</span></li>
</ul>
<p>Floats and doubles are not equidistant:</p>
<p><img src="images/fltscale-wh.png" alt="floating point" style="width: 100%"> Source: <a href="http://www.volkerschatz.com/science/float.html">What you never wanted to know about floating point but will be forced to find out</a></p>
<p><strong>Machine Epsilon</strong></p>
<p>Half the distance between 1 and the next larger number. This can vary by computer. IEEE standards for double precision specify <span class="math display">\[ \varepsilon_{machine} = 2^{-53} \approx 1.11 \times 10^{-16}\]</span></p>
<p><strong>Two important properties of Floating Point Arithmetic</strong>:</p>
<ul>
<li><p>The difference between a real number <span class="math inline">\(x\)</span> and its closest floating point approximation <span class="math inline">\(fl(x)\)</span> is always smaller than <span class="math inline">\(\varepsilon_{machine}\)</span> in relative terms. For some <span class="math inline">\(\varepsilon\)</span>, where <span class="math inline">\(\lvert \varepsilon \rvert \leq \varepsilon_{machine}\)</span>, <span class="math display">\[fl(x)=x \cdot (1 + \varepsilon)\]</span></p></li>
<li><p>Where * is any operation (<span class="math inline">\(+, -, \times, \div\)</span>), and <span class="math inline">\(\circledast\)</span> is its floating point analogue, <span class="math display">\[ x \circledast y = (x * y)(1 + \varepsilon)\]</span> for some <span class="math inline">\(\varepsilon\)</span>, where <span class="math inline">\(\lvert \varepsilon \rvert \leq \varepsilon_{machine}\)</span> That is, every operation of floating point arithmetic is exact up to a relative error of size at most <span class="math inline">\(\varepsilon_{machine}\)</span></p></li>
</ul>
</section>
<section id="history" class="level4">
<h4 class="anchored" data-anchor-id="history">History</h4>
<p>Floating point arithmetic may seem like a clear choice in hindsight, but there have been many, many ways of storing numbers: - fixed-point arithmetic - logarithmic and semilogarithmic number systems - continued-fractions - rational numbers - possibly infinite strings of rational numbers - level-index number systems - fixed-slash and floating-slash number systems - 2-adic numbers</p>
<p>For references, see <a href="https://perso.ens-lyon.fr/jean-michel.muller/chapitre1.pdf">Chapter 1</a> (which is free) of the <a href="http://www.springer.com/gp/book/9780817647049">Handbook of Floating-Point Arithmetic</a>. Yes, there is an entire 16 chapter book on floating point!</p>
<p>Timeline History of Floating Point Arithmetic: - ~1600 BC: Babylonian radix-60 system was earliest floating-point system (Donald Knuth). Represented the significand of a radix-60 floating-point representation (if ratio of two numbers is a power of 60, represented the same) - 1630 Slide rule. Manipulate only significands (radix-10) - 1914 Leonardo Torres y Quevedo described an electromechanical implementation of Babbage’s Analytical Engine with Floating Point Arithmetic. - 1941 First real, modern implementation. Konrad Zuse’s Z3 computer. Used radix-2, with 14 bit significand, 7 bit exponents, and 1 sign bit. - 1985 IEEE 754-1985 Standard for Binary Floating-Point Arithmetic released. Has increased accuracy, reliability, and portability. <a href="https://people.eecs.berkeley.edu/~wkahan/">William Kahan</a> played leading role.</p>
<p>“Many different ways of approximating real numbers on computers have been introduced.. And yet, floating-point arithmetic is <strong>by far the most widely used</strong> way of representing real numbers in modern computers. Simulating an infinite, continuous set (the real numbers) with a finite set (the “machine numbers”) is not a straightforward task: <strong>clever compromises must be found between, speed, accuracy, dynamic range, ease of use and implementation, and memory</strong>. It appears that floating-point arithmetic, with adequately chosen parameters (radix, precision, extremal exponents, etc.), is a very good compromise for most numerical applications.”</p>
<p>Although a radix value of 2 (binary) seems like the pretty clear winner now for computers, a variety of other radix values have been used at various point:</p>
<ul>
<li>radix-8 used by early machines PDP-10, Burroughs 570 and 6700</li>
<li>radix-16 IBM 360</li>
<li>radix-10 financial calculations, pocket calculators, Maple</li>
<li>radix-3 Russian SETUN computer (1958). Benefits: minimizes beta x p (symbols x digits), for a fixed largest representable number beta^p - 1. Rounding = truncation</li>
<li>radix-2 most common. Reasons: easy to implement. Studies have shown (with implicit leading bit) this gives better worst-case or average accuracy than all other radices.</li>
</ul>
</section>
</section>
<section id="conditioning-and-stability" class="level3">
<h3 class="anchored" data-anchor-id="conditioning-and-stability">Conditioning and Stability</h3>
<p>Since we can not represent numbers exactly on a computer (due to the finiteness of our storage, and the gaps between numbers in floating point architecture), it becomes important to know <em>how small perturbations in the input to a problem impact the output</em>.</p>
<p><strong>“A stable algorithm gives nearly the right answer to nearly the right question.”</strong> –Trefethen</p>
<p><strong>Conditioning</strong>: perturbation behavior of a mathematical problem (e.g.&nbsp;least squares)</p>
<p><strong>Stability</strong>: perturbation behavior of an algorithm used to solve that problem on a computer (e.g.&nbsp;least squares algorithms, householder, back substitution, gaussian elimination)</p>
<p>Example: Eigenvalues of a Matrix</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.linalg <span class="im">as</span> la </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">1.</span>, <span class="dv">1000</span>], [<span class="dv">0</span>, <span class="dv">1</span>]])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">1000</span>], [<span class="fl">0.001</span>, <span class="dv">1</span>]])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[    1.  1000.]
 [    0.     1.]]
[[    1.     1000.   ]
 [    0.001     1.   ]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(suppress<span class="op">=</span><span class="va">True</span>, precision<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>wA, vrA <span class="op">=</span> la.eig(A)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>wB, vrB <span class="op">=</span> la.eig(B)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>wA, wB</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Reminder: Two properties of Floating Point Arithmetic</strong></p>
<ul>
<li><p>The difference between a real number <span class="math inline">\(x\)</span> and its closest floating point approximation <span class="math inline">\(fl(x)\)</span> is always smaller than <span class="math inline">\(\varepsilon_{machine}\)</span> in relative terms.</p></li>
<li><p>Every operation <span class="math inline">\(+, -, \times, \div\)</span> of floating point arithmetic is exact up to a relative error of size at most <span class="math inline">\(\varepsilon_{machine}\)</span></p></li>
</ul>
<p>Examples we’ll see: - Classical vs Modified Gram-Schmidt accuracy - Gram-Schmidt vs.&nbsp;Householder (2 different ways of computing QR factorization), how orthogonal the answer is - Condition of a system of equations</p>
</section>
<section id="approximation-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="approximation-accuracy">Approximation accuracy</h3>
<p>It’s rare that we need to do highly accurate matrix computations at scale. In fact, often we’re doing some kind of machine learning, and less accurate approaches can prevent overfitting.</p>
<p>If we accept some decrease in accuracy, then we can often increase speed by orders of magnitude (and/or decrease memory use) by using approximate algorithms. These algorithms typically give a correct answer with some probability. By rerunning the algorithm multiple times you can generally increase that probability multiplicatively!</p>
<p><strong>Example</strong>: A <strong>bloom filter</strong> allows searching for set membership with 1% false positives, using &lt;10 bits per element. This often represents reductions in memory use of thousands of times.</p>
<p><img src="images/bloom_filter.png" alt="Bloom Filters" style="width: 60%"></p>
<p>The false positives can be easily handled by having a second (exact) stage check all returned items - for rare items this can be very effective. For instance, many web browsers use a bloom filter to create a set of blocked pages (e.g.&nbsp;pages with viruses), since blocked web pages are only a small fraction of the whole web. A false positive can be handled here by taking anything returned by the bloom filter and checking against a web service with the full exact list. (See this <a href="https://llimllib.github.io/bloomfilter-tutorial/">bloom filter tutorial</a> for more details).</p>
</section>
<section id="expensive-errors" class="level3">
<h3 class="anchored" data-anchor-id="expensive-errors">Expensive Errors</h3>
<p><em>The below examples are from Greenbaum &amp; Chartier.</em></p>
<p>European Space Agency spent 10 years and $7 billion on the Ariane 5 Rocket.</p>
<p>What can happen when you try to fit a 64 bit number into a 16 bit space (integer overflow):</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> YouTubeVideo</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>YouTubeVideo(<span class="st">"PK_yguLapgA"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/PK_yguLapgA" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
<p>Here is a floating point error that cost Intel $475 million:</p>
<p><a href="http://www.nytimes.com/1994/11/24/business/company-news-flaw-undermines-accuracy-of-pentium-chips.html">1994 NYTimes article about Intel Pentium Error</a> <img src="images/pentium_nytimes.png" class="img-fluid" alt="article"></p>
<p><strong>Resources</strong>: See Lecture 13 of Trefethen &amp; Bau and Chapter 5 of Greenbaum &amp; Chartier for more on Floating Point Arithmetic</p>
</section>
</section>
<section id="memory-use" class="level2">
<h2 class="anchored" data-anchor-id="memory-use">Memory Use</h2>
<section id="sparse-vs-dense" class="level3">
<h3 class="anchored" data-anchor-id="sparse-vs-dense">Sparse vs Dense</h3>
<p>Above we covered how <em>numbers</em> are stored, now let’s talk about how <em>matrices</em> are stored. A key way to save memory (and computation) is not to store all of your matrix. Instead, just store the non-zero elements. This is called <strong>sparse</strong> storage, and it is well suited to sparse matrices, that is, matrices where most elements are zero.</p>
<p><img src="images/sparse.png" alt="floating point" style="width: 50%"></p>
<p>Here is an example of the matrix from a finite element problem, which shows up in engineering (for instance, when modeling the air-flow around a plane). In this example, the non-zero elements are black and the zero elements are white: <img src="images/Finite_element_sparse_matrix.png" alt="floating point" style="width: 50%"> <a href="https://commons.wikimedia.org/w/index.php?curid=2245335">Source</a></p>
<p>There are also special types of structured matrix, such as diagonal, tri-diagonal, hessenberg, and triangular, which each display particular patterns of sparsity, which can be leveraged to reduce memory and computation.</p>
<p>The opposite of a sparse matrix is a <strong>dense</strong> matrix, along with dense storage, which simply refers to a matrix containing mostly non-zeros, in which every element is stored explicitly. Since sparse matrices are helpful and common, numerical linear algebra focuses on maintaining sparsity through as many operations in a computation as possible.</p>
</section>
</section>
<section id="speed" class="level2">
<h2 class="anchored" data-anchor-id="speed">Speed</h2>
<p>Speed differences come from a number of areas, particularly: - Computational complexity - Vectorization - Scaling to multiple cores and nodes - Locality</p>
<section id="computational-complexity" class="level3">
<h3 class="anchored" data-anchor-id="computational-complexity">Computational complexity</h3>
<p>If you are unfamiliar with computational complexity and <span class="math inline">\(\mathcal{O}\)</span> notation, you can read about it <a href="https://www.interviewcake.com/article/java/big-o-notation-time-and-space-complexity">on Interview Cake</a> and <a href="https://www.codecademy.com/courses/big-o/0/3">practice on Codecademy</a>. Algorithms are generally expressed in terms of computation complexity with respect to the number of rows and number of columns in the matrix. E.g. you may find an algorithm described as <span class="math inline">\(\mathcal{O(n^2m)}\)</span>.</p>
</section>
<section id="vectorization" class="level3">
<h3 class="anchored" data-anchor-id="vectorization">Vectorization</h3>
<p>Modern CPUs and GPUs can apply an operation to multiple elements at once on a single core. For instance, take the exponent of 4 floats in a vector in a single step. This is called SIMD. You will not be explicitly writing SIMD code (which tends to require assembly language or special C “intrinsics”), but instead will use vectorized operations in libraries like numpy, which in turn rely on specially tuned vectorized low level linear algebra APIs (in particular, BLAS, and LAPACK).</p>
<section id="matrix-computation-packages-blas-and-lapack" class="level4">
<h4 class="anchored" data-anchor-id="matrix-computation-packages-blas-and-lapack">Matrix Computation Packages: BLAS and LAPACK</h4>
<p><a href="http://www.netlib.org/blas/">BLAS (Basic Linear Algebra Subprograms)</a>: specification for low-level matrix and vector arithmetic operations. These are the standard building blocks for performing basic vector and matrix operations. BLAS originated as a Fortran library in 1979. Examples of BLAS libraries include: AMD Core Math Library (ACML), ATLAS, Intel Math Kernel Library (MKL), and OpenBLAS.</p>
<p><a href="http://www.netlib.org/lapack/">LAPACK</a> is written in Fortran, provides routines for solving systems of linear equations, eigenvalue problems, and singular value problems. Matrix factorizations (LU, Cholesky, QR, SVD, Schur). Dense and banded matrices are handled, but not general sparse matrices. Real and complex, single and double precision.</p>
<p>1970s and 1980s: EISPACK (eigenvalue routines) and LINPACK (linear equations and linear least-squares routines) libraries</p>
<p><strong>LAPACK original goal</strong>: make LINAPCK and EISPACK run efficiently on shared-memory vector and parallel processors and exploit cache on modern cache-based architectures (initially released in 1992). EISPACK and LINPACK ignore multi-layered memory hierarchies and spend too much time moving data around.</p>
<p>LAPACK uses highly optimized block operations implementations (which much be implemented on each machine) LAPACK written so as much of the computation as possible is performed by BLAS.</p>
</section>
</section>
<section id="locality" class="level3">
<h3 class="anchored" data-anchor-id="locality">Locality</h3>
<p>Using slower ways to access data (e.g.&nbsp;over the internet) can be up to a billion times slower than faster ways (e.g.&nbsp;from a register). But there’s much less fast storage than slow storage. So once we have data in fast storage, we want to do any computation required at that time, rather than having to load it multiple times each time we need it. In addition, for most types of storage its much faster to access data items that are stored next to each other, so we should try to always use any data stored nearby that we know we’ll need soon. These two issues are known as locality.</p>
<section id="speed-of-different-types-of-memory" class="level4">
<h4 class="anchored" data-anchor-id="speed-of-different-types-of-memory">Speed of different types of memory</h4>
<p>Here are some <em>numbers everyone should know</em> (from the legendary <a href="http://static.googleusercontent.com/media/research.google.com/en/us/people/jeff/stanford-295-talk.pdf">Jeff Dean</a>): - L1 cache reference 0.5 ns - L2 cache reference 7 ns - Main memory reference/RAM 100 ns - Send 2K bytes over 1 Gbps network 20,000 ns - Read 1 MB sequentially from memory 250,000 ns - Round trip within same datacenter 500,000 ns - Disk seek 10,000,000 ns - Read 1 MB sequentially from network 10,000,000 ns - Read 1 MB sequentially from disk 30,000,000 ns - Send packet CA-&gt;Netherlands-&gt;CA 150,000,000 ns</p>
<p>And here is an updated, interactive <a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html">version</a>, which includes a timeline of how these numbers have changed.</p>
<p><strong>Key take-away</strong>: Each successive memory type is (at least) an order of magnitude worse than the one before it. Disk seeks are <strong>very slow</strong>.</p>
<p>This video has a great example of showing several ways you could compute the blur of a photo, with various trade-offs. Don’t worry about the C code that appears, just focus on the red and green moving pictures of matrix computation.</p>
<p>Although the video is about a new language called Halide, it is a good illustration the issues it raises are universal. Watch minutes 1-13:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> YouTubeVideo</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>YouTubeVideo(<span class="st">"3uiEyEKji0M"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/3uiEyEKji0M" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
<p>Locality is hard. Potential trade-offs: - redundant computation to save memory bandwidth - sacrificing parallelism to get better reuse</p>
</section>
<section id="temporaries" class="level4">
<h4 class="anchored" data-anchor-id="temporaries">Temporaries</h4>
<p>The issue of “temporaries” occurs when the result of a calculation is stored in a temporary variable in RAM, and then that variable is loaded to do another calculation on it. This is many orders of magnitude slower than simply keeping the data in cache or registers and doing all necessary computations before storing the final result in RAM. This is particularly an issue for us since numpy generally creates temporaries for every single operation or function it does. E.g. <span class="math inline">\(a=b\cdot c^2+ln(d)\)</span> will create four temporaries (since there are four operations and functions).</p>
</section>
</section>
<section id="scaling-to-multiple-cores-and-nodes" class="level3">
<h3 class="anchored" data-anchor-id="scaling-to-multiple-cores-and-nodes">Scaling to multiple cores and nodes</h3>
<p>We have a separate section for scalability, but it’s worth noting that this is also important for speed - if we can’t scale across all the computing resources we have, we’ll be stuck with slower computation.</p>
</section>
</section>
<section id="scalability-parallelization" class="level2">
<h2 class="anchored" data-anchor-id="scalability-parallelization">Scalability / parallelization</h2>
<p>Often we’ll find that we have more data than we have memory to handle, or time to compute. In such a case we would like to be able to scale our algorithm across <a href="http://www.makeuseof.com/tag/processor-core-makeuseof-explains-2/">multiple cores</a> (within one computer) or nodes (i.e.&nbsp;multiple computers on a network). We will not be tackling multi-node scaling in this course, although we will look at scaling across multiple cores (called parallelization). In general, scalable algorithms are those where the input can be broken up into smaller pieces, each of which are handled by a different core/computer, and then are put back together at the end.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>